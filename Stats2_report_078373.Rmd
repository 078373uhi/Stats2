---
title: "078373_Stats2_Report"
author: "Michelle Paterson"
date: "29/03/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r setup, include=FALSE}
# Install packages
library(tidyverse)
library(tidytext)
install.packages("gutenbergr")
library(gutenbergr)
library(dplyr)
library(ggplot2)
library(wordcloud2)
library(viridisLite)
library(rvest)
library(patchwork)
library(stringr)
library(widyr)
library(wordcloud)
library(igraph)
library(ggraph)
library(reshape2)
```

```{r setup, include=FALSE}
# Read in data
read.csv("navy_comms.csv")
read.csv("navy_extra.csv")

# load in texts
battle <- read_lines("https://www.gutenberg.org/files/54441/54441-0.txt", skip = 214)
head(battle, 10)

battle_text <- tibble(source='Battle',text = battle)
head(battle_text)

navybook <- read_lines("https://www.gutenberg.org/cache/epub/41677/pg41677.txt", skip = 264)
head(navybook, 10)

navy_text <- tibble(source='Navy',text = navybook)
head(navy_text)

flag <- read_lines("https://www.gutenberg.org/cache/epub/19849/pg19849.txt", skip = 426)
head(flag, 10)

flag_text <- tibble(source='Flag',text = flag)
head(flag_text)

# collate the texts together into a corpus
BritNavy <- rbind(battle_text, navy_text, flag_text)

# tidy up the text 
tidy_BN <- BritNavy %>%
  unnest_tokens(word, text)

# remove stop words
tidy_BN <- tidy_BN %>%
  anti_join(stop_words)
```

```{r showBN, include=FALSE}
tidy_BN

```
## Sentiment Analysis
Three books were used for the sentiment analysis with the common theme of the British Navy.  These were The British Navy Book by Cyril Field, The British Navy in Battle by Arthur Joseph Hungerford Pollen and Flag and Fleet: How the British Navy Won the Freedom of the Seas by William Wood.

```{r countBN, echo=FALSE}
#count unique words then group by source (book)
tidy_BN %>%
  count(word, sort=TRUE)

tidy_BN_count <- tidy_BN %>%
  group_by(source) %>%
  count(word, sort=TRUE)

tidy_BN_count

```

### Word Count

The British Navy Book is the book with the most words (41,909) followed by The British Navy in Battle (40,616) and Flag and Fleet has the least by quite a lot (32,834).  When looking at unique words used this is reflected too: The British Navy Book uses 9,901 unique words; The British Navy in Battle uses 7,182; and Flag and Fleet uses 6,803. 


```{r countbook}
#count words then group by source (book)
count(tidy_BN, source)

```

```{r countuniq}
#count words then group by source (book)
count(tidy_BN, source)

#count unique words per book

tidy_BN %>%
  filter(source == "Battle") %>%
  count(word, sort=TRUE)

tidy_BN %>%
  filter(source == "Navy") %>%
  count(word, sort=TRUE)

tidy_BN %>%
  filter(source == "Flag") %>%
  count(word, sort=TRUE)

```
This plot and wordcloud show the highest frequency words when the books are combined.

```{r plotBN}
tidy_BN %>%
  count(word, sort = TRUE) %>%
  filter(n > 250) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word, fill=word)) +
  geom_col() +
  labs(title='Word frequency for the three books together',
       y = NULL, x= "word count") +
  theme(legend.position="none")
```

```{r cloudBN}
colour_pal <- turbo(n=100)

wc_data <- tidy_BN %>%
  count(word)  %>%
  filter(n > 100)   # only include words that appear more than a hundred times
wordcloud2(wc_data, shape='circle', size=0.5, color=colour_pal)
```



```{r plotbattle, echo=FALSE}
plot_battle <- tidy_BN %>%
  filter(source == "Battle") %>%
  count(word, sort = TRUE) %>%
  filter(n > 100) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word, fill=word)) +
  geom_col() +
  labs(title='The British Navy in Battle',
       y = NULL, x= "word count") +
  theme(legend.position="none")

plot_navy <- tidy_BN %>%
  filter(source == "Navy") %>%
  count(word, sort = TRUE) %>%
  filter(n > 100) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word, fill=word)) +
  geom_col() +
  labs(title='The British Navy Book',
       y = NULL, x= "word count") +
  theme(legend.position="none")

plot_flag <- tidy_BN %>%
  filter(source == "Flag") %>%
  count(word, sort = TRUE) %>%
  filter(n > 100) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word, fill=word)) +
  geom_col() +
  labs(title='Flag and Fleet',
       y = NULL, x= "word count") +
  theme(legend.position="none")
```

```{r countplots}
plot_battle + plot_navy + plot_flag
```

# Show word importance by Tf-idf weighting for all Presidents
tidy_pres2_count %>%
  bind_tf_idf(word, source, n) %>%
  arrange(desc(tf_idf)) 

```{r import}
# Show word importance by Tf-idf weighting for all books
tidy_BN_count %>%
  bind_tf_idf(word, source, n) %>%
  arrange(desc(tf_idf)) 
```

```{r importplot}
# Show word importance by Tf-idf weighting for each book
plot_importance <- tidy_BN_count %>%
  bind_tf_idf(word, source, n) %>%
  group_by(source) %>%
  top_n(10, tf_idf) %>%
  ungroup()
ggplot(plot_importance, aes(reorder(word, tf_idf), tf_idf, fill = source)) +
  geom_col(show.legend = FALSE) + labs(x = NULL, y = "tf-idf") +
  facet_wrap( ~ source, ncol = 5, scales = "free") + coord_flip()
```
```{r wordnetwork, echo=FALSE}
set.seed(1)

a <- grid::arrow(type='closed', length = unit(0.25,"cm"))

navy_net <- tidy_BN_count %>%
  filter(n>150) %>%
  filter(source == "Navy") %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(),
                 arrow = a, end_cap = circle(0.25, "cm")) +
  geom_node_point(colour="lightblue", size = 5) +
  geom_node_text(aes(label = name), repel = TRUE) +
  theme(legend.position="none")+
  theme_void() +
  labs(title = "Word Network",
       subtitle = "The British Navy Book",
       x = "", y = "")

flag_net <- tidy_BN_count %>%
  filter(n>150) %>%
  filter(source == "Flag") %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(),
                 arrow = a, end_cap = circle(0.25, "cm")) +
  geom_node_point(colour="lightblue", size = 5) +
  geom_node_text(aes(label = name), repel = TRUE) +
  theme(legend.position="none")+
  theme_void() +
  labs(title = "Word Network",
       subtitle = "Flag and Fleet",
       x = "", y = "")

battle_net <- tidy_BN_count %>%
  filter(n>150) %>%
  filter(source == "Battle") %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(),
                 arrow = a, end_cap = circle(0.25, "cm")) +
  geom_node_point(colour="lightblue", size = 5) +
  geom_node_text(aes(label = name), repel = TRUE) +
  theme(legend.position="none")+
  theme_void() +
  labs(title = "Word Network",
       subtitle = "The British Navy in Battle",
       x = "", y = "")
```

```{r netplots}
navy_net + battle_net + flag_net
```





























```{r countnavy}
tidy_navy %>%
  count(word, sort=TRUE)
```
```{r plotnavy, echo=FALSE}
tidy_navy %>%
  count(word, sort = TRUE) %>%
  filter(n > 75) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word, fill=word)) +
  geom_col() +
  labs(title='Word frequency for The British Navy Book',
       y = NULL, x= "word count") +
  theme(legend.position="none")
```
```{r countflag}
tidy_flag %>%
  count(word, sort=TRUE)
```

```{r plotflag, echo=FALSE}
tidy_flag %>%
  count(word, sort = TRUE) %>%
  filter(n > 75) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word, fill=word)) +
  geom_col() +
  labs(title='Word frequency for Flag and Fleet: How the British Navy Won the Freedom of the Seas',
       y = NULL, x= "word count") +
  theme(legend.position="none")
```

```{r cloudbattle}
colour_pal <- turbo(n=100)

wc_data <- tidy_battle %>%
  count(word)  %>%
  filter(n > 10)   # only include words that appear more than ten times
wordcloud2(wc_data, shape='circle', size=0.5, color=colour_pal)
```

```{r cloudnavy}
colour_pal <- turbo(n=100)

wc_data <- tidy_navy %>%
  count(word)  %>%
  filter(n > 10)   # only include words that appear more than ten times
wordcloud2(wc_data, shape='circle', size=0.5, color=colour_pal)
```

```{r cloudflag}
colour_pal <- turbo(n=100)

wc_data <- tidy_flag %>%
  count(word)  %>%
  filter(n > 10)   # only include words that appear more than ten times
wordcloud2(wc_data, shape='circle', size=0.5, color=colour_pal)
```







